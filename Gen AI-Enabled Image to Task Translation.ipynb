{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700a9e7a-8299-4720-8923-c2a518ef33d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud auth application-default login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70b5461-a501-4295-a888-2cdda735c0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a7c9c0-8a11-4b47-9a35-219fd84c7ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performing Necessary Imports\n",
    "import os\n",
    "import configparser\n",
    "from google.cloud import storage\n",
    "import vertexai\n",
    "from vertexai.preview.generative_models import GenerativeModel, Part\n",
    "import pandas as pd\n",
    "from xlsxwriter.workbook import Workbook\n",
    "from datetime import datetime\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df115825-1e10-429a-b5e1-c3ab55fa15c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration from config.ini\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "# Extract values from the DEFAULT section\n",
    "project_name = config['DEFAULT']['project_name']\n",
    "region = config['DEFAULT']['region']\n",
    "bucket_name = config['DEFAULT']['bucket_name']\n",
    "sample_images_path = config['DEFAULT']['sample_images_path']\n",
    "\n",
    "def create_bucket_if_not_exists(bucket_name, project_name, region):\n",
    "    \"\"\"Create a GCS bucket if it does not exist.\"\"\"\n",
    "    storage_client = storage.Client(project=project_name)\n",
    "    bucket = storage_client.lookup_bucket(bucket_name)\n",
    "    \n",
    "    if bucket:\n",
    "        print(f\"Bucket {bucket_name} already exists.\")\n",
    "    else:\n",
    "        bucket = storage_client.create_bucket(bucket_name, location=region)\n",
    "        print(f\"Bucket {bucket_name} created in region {region}.\")\n",
    "    \n",
    "    return bucket\n",
    "\n",
    "def delete_all_files_from_bucket(bucket_name):\n",
    "    \"\"\"Delete all files from the specified GCS bucket.\"\"\"\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    \n",
    "    # List and delete all blobs in the bucket\n",
    "    blobs = bucket.list_blobs()\n",
    "    for blob in blobs:\n",
    "        blob.delete()\n",
    "        print(f\"Deleted {blob.name} from bucket {bucket_name}.\")\n",
    "\n",
    "def upload_files_to_bucket(bucket_name, folder_path):\n",
    "    \"\"\"Upload all files from a specified folder to the given GCS bucket.\"\"\"\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    \n",
    "    # Iterate over all files in the specified folder and upload them to the bucket\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            blob = bucket.blob(file_name)\n",
    "            blob.upload_from_filename(file_path)\n",
    "            print(f\"Uploaded {file_name} to bucket {bucket_name}.\")\n",
    "\n",
    "# Create the bucket if it doesn't exist\n",
    "create_bucket_if_not_exists(bucket_name, project_name, region)\n",
    "\n",
    "# Delete all existing files from the bucket\n",
    "delete_all_files_from_bucket(bucket_name)\n",
    "\n",
    "# Upload files from the sample images path to the bucket\n",
    "upload_files_to_bucket(bucket_name, sample_images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575090a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize logger\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "def is_empty_or_whitespace(s):\n",
    "    \"\"\"Function to check if a string is empty or consists only of whitespace.\"\"\"\n",
    "    return s is None or s.isspace() or not s\n",
    "\n",
    "def delete_all_files_in_folder(folder_path):\n",
    "    \"\"\"Delete all files in the specified local folder.\"\"\"\n",
    "    if os.path.exists(folder_path):\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            if os.path.isfile(file_path):\n",
    "                os.remove(file_path)\n",
    "                logger.info(f\"Deleted local file: {file_name}\")\n",
    "    else:\n",
    "        logger.warning(f\"The folder {folder_path} does not exist.\")\n",
    "\n",
    "def generate_text_response(client, gcs_path, context, task, output_format, default_prompt_flag):\n",
    "    \"\"\"Generates text response based on image content using Vertex AI.\"\"\"\n",
    "    # Initialize Vertex AI\n",
    "    vertexai.init(project=project_name_param, location=region)\n",
    "\n",
    "    # Load the model\n",
    "    multimodal_model = GenerativeModel(\"gemini-pro-vision\")\n",
    "    #multimodal_model = GenerativeModel(\"gemini-1.5-flash\")\n",
    "    \n",
    "\n",
    "    # Default prompt setup\n",
    "    default_prompt = \"\"\"\n",
    "        Context : Need to convert flowchart to Steps\n",
    "        Task : - Generate a JSON structure representing a list of steps. Each step Desciption must have at least 10 words.\n",
    "               - Additional Steps can be created to highlight relation between each steps.\n",
    "               - Steps must be reference other steps if there are dependencies.\n",
    "               - Each step should be a dictionary with the following keys:\n",
    "                \"Step number\": an integer representing the step number.\n",
    "                \"Step Description\": a string describing the step with at least 10 words.\n",
    "        Format :\n",
    "                [\n",
    "                    {\n",
    "                      \"Step number\":1,\n",
    "                      \"Step Description\": \"Discuss project concept with stakeholders.\"\n",
    "                    },\n",
    "                    {\n",
    "                      \"Step number\":2,\n",
    "                      \"Step Description\": \"Do stakeholders approve of project concept?\"\n",
    "                    }\n",
    "                ]            \n",
    "    \"\"\"\n",
    "\n",
    "    # Use default prompt if necessary\n",
    "    prompt = default_prompt if default_prompt_flag else \"\\n\".join([context, task, output_format])\n",
    "\n",
    "    # Query the model\n",
    "    response = multimodal_model.generate_content(\n",
    "        [\n",
    "            Part.from_uri(gcs_path, mime_type=\"image/jpeg\"),\n",
    "            prompt\n",
    "        ],\n",
    "        generation_config={\n",
    "            \"max_output_tokens\": 2048,\n",
    "            \"temperature\": 0.4,\n",
    "            \"top_p\": 1,\n",
    "            \"top_k\": 32\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Return the text part of the response\n",
    "    return response.text\n",
    "\n",
    "def process_image_file(client, bucket_name, file_name, local_file_path, writer):\n",
    "    \"\"\"Process an image file by generating a response and saving it to an Excel sheet.\"\"\"\n",
    "    sheet_name = file_name.split('.')[0][:30]\n",
    "    file_name = file_name.split('/')[-1]\n",
    "    logger.info(f\"Processing file: {file_name} in bucket {bucket_name}\")\n",
    "\n",
    "    gcs_file_path = f\"gs://{bucket_name}/{file_name}\"\n",
    "    local_image_path = os.path.join(local_file_path, file_name)\n",
    "\n",
    "    # Generate the text response\n",
    "    text = generate_text_response(client, gcs_file_path, context, task, output_format, default_prompt_flag)\n",
    "\n",
    "    try:\n",
    "        final_dictionary = json.loads(text) \n",
    "        df = pd.DataFrame(final_dictionary)\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        workbook = writer.book\n",
    "        worksheet = writer.sheets[sheet_name]\n",
    "\n",
    "        # Formatting Excel sheet\n",
    "        num_rows, num_cols = df.shape\n",
    "        header_format = workbook.add_format({\n",
    "            'bold': True,\n",
    "            'text_wrap': True,\n",
    "            'valign': 'vcenter',\n",
    "            'align': 'center',\n",
    "            'fg_color': '#00FFFF',\n",
    "            'border': 1,\n",
    "            'font_size': 12,\n",
    "            'font_color': 'black'\n",
    "        })\n",
    "\n",
    "        for col_num, value in enumerate(df.columns.values):\n",
    "            worksheet.write(0, col_num, value, header_format)\n",
    "\n",
    "        # Apply cell formatting\n",
    "        cell_format = workbook.add_format({'border': 1})\n",
    "        worksheet.conditional_format(1, 0, num_rows, num_cols - 1, {'type': 'no_blanks', 'format': cell_format})\n",
    "        worksheet.autofit()\n",
    "\n",
    "        # Download and insert image into Excel\n",
    "        bucket = client.bucket(bucket_name)\n",
    "        blob = bucket.blob(file_name)\n",
    "        blob.download_to_filename(local_image_path)\n",
    "        worksheet.insert_image(num_rows + 2, 0, local_image_path, {'x_offset': 15, 'y_offset': 10, 'x_scale': 0.2, 'y_scale': 0.2})\n",
    "        logger.info(f\"Processed file: {file_name}\")\n",
    "\n",
    "    except ValueError as e:\n",
    "        logger.error(f\"Error parsing JSON: {e}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred: {e}\")\n",
    "        \n",
    "    logger.info(\"Sleeping for 30 seconds before processing the next file...\")\n",
    "    time.sleep(30)\n",
    "    \n",
    "def image_to_task_generator(project_name_param, region, bucket_name_param, local_file_fixed_path, output_file_path, output_file_name_prefix, output_file_name_suffix, context, task, output_format):\n",
    "    \"\"\"Main function to process images and generate tasks.\"\"\"\n",
    "    client = storage.Client(project=project_name_param)\n",
    "    extract_datetime = datetime.today().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_file_name = f'{output_file_path}\\\\{output_file_name_prefix}_{extract_datetime}_{output_file_name_suffix}.xlsx'\n",
    "    writer = pd.ExcelWriter(output_file_name, engine='xlsxwriter')\n",
    "\n",
    "    # Clear the local directory before downloading new images\n",
    "    delete_all_files_in_folder(local_file_fixed_path)\n",
    "\n",
    "    blob_list = list(client.list_blobs(bucket_name_param))\n",
    "    \n",
    "    if not blob_list:\n",
    "        logger.warning(f\"No files found in the bucket: {bucket_name_param}\")\n",
    "    else:\n",
    "        for blob in blob_list:\n",
    "            file_name = str(blob.name)\n",
    "            _, file_extension = os.path.splitext(file_name)\n",
    "            if file_extension.lower() in ['.jpg', '.jpeg', '.png']:\n",
    "                process_image_file(client, bucket_name_param, file_name, local_file_fixed_path, writer)\n",
    "            else:\n",
    "                logger.warning(f\"Invalid file format for {file_name}. Only jpg and png files are supported.\")\n",
    "\n",
    "        writer.close()\n",
    "        logger.info(f\"Generated Output File: {output_file_name}\")\n",
    "\n",
    "def load_config():\n",
    "    \"\"\"Load configuration from the config.ini file.\"\"\"\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read('config.ini')\n",
    "    return config['DEFAULT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fa7224",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        config = load_config()\n",
    "    \n",
    "        project_name_param = config.get('project_name')\n",
    "        region = config.get('region')\n",
    "        bucket_name_param = config.get('bucket_name')\n",
    "        local_file_fixed_path = config.get('image_file_path')\n",
    "        output_file_path = config.get('output_file_path')\n",
    "        log_folder_path = config.get('log_folder_path')\n",
    "        output_file_name_prefix = config.get('output_file_name_prefix')\n",
    "        default_prompt_flag=False\n",
    "        \n",
    "        # Configure the logging settings\n",
    "        logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "        logger = logging.getLogger(__name__)\n",
    "        \n",
    "        # Create the log folder if it doesn't exist\n",
    "        os.makedirs(log_folder_path, exist_ok=True)\n",
    "        \n",
    "        # Create a file handler with a dynamic log file name and folder path\n",
    "        log_file_name = 'image_to_task_gen_app.log'\n",
    "        log_file_path = os.path.join(log_folder_path, log_file_name)\n",
    "        file_handler = logging.FileHandler(log_file_path, mode='a')\n",
    "        file_handler.setLevel(logging.INFO)\n",
    "        \n",
    "        # Create a formatter and add it to the file handler\n",
    "        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "        file_handler.setFormatter(formatter)\n",
    "        \n",
    "        # Add the file handler to the logger\n",
    "        logger.addHandler(file_handler)    \n",
    "    \n",
    "        # CTF Format used in prompt designing.Copy from here during custom input\n",
    "        \"\"\"\n",
    "        Context : Need to convert Flowchart to Steps\n",
    "        \n",
    "        Task : Generate a JSON structure representing a list of steps.\n",
    "                Each step should be a dictionary with the following keys:\n",
    "                    \"Step number\": an integer representing the step number.\n",
    "                    \"Step Description\": a string describing the step.\n",
    "            \n",
    "        Format : \n",
    "                        [\n",
    "                            {\n",
    "                              \"Step number\":1,\n",
    "                              \"Step Description\": \"Discuss project concept with stakeholders.\"\n",
    "                            },\n",
    "                            {\n",
    "                              \"Step number\":2,\n",
    "                              \"Step Description\": \"Do stakeholders approve of project concept?\"\n",
    "                            }\n",
    "                        ]     \n",
    "        \"\"\"\n",
    "        \n",
    "                    \n",
    "        # Uncomment the following lines for user input\n",
    "        context = input(\"Enter the context: \")\n",
    "        task = input(\"Enter the task description: \")\n",
    "        output_format = input(\"Enter the output format (in JSON structure): \")\n",
    "    \n",
    "        if any(is_empty_or_whitespace(param) for param in [context, task, output_format]):\n",
    "            logger.info(\"Proceeding with default_prompt\")\n",
    "            output_file_name_suffix = 'DefaultPrompt'\n",
    "            default_prompt_flag=True\n",
    "        else:\n",
    "            logger.info(\"Proceeding with custom prompt\")\n",
    "            output_file_name_suffix = 'CustomPrompt'\n",
    "        \n",
    "        # Invoking the image_to_task_generator function with the specified parameters\n",
    "        image_to_task_generator(\n",
    "            project_name_param,\n",
    "            region,\n",
    "            bucket_name_param,\n",
    "            local_file_fixed_path,\n",
    "            output_file_path,\n",
    "            output_file_name_prefix,\n",
    "            output_file_name_suffix,\n",
    "            context,\n",
    "            task,\n",
    "            output_format\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Log the exception and any additional information you want\n",
    "        logger.error(f\"An error occurred: {str(e)}\", exc_info=True)\n",
    "    finally:\n",
    "        file_handler.close()\n",
    "        logging.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f758b969",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
